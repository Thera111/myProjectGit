# 性能测试指南

本文档提供了热词统计与分析系统性能测试的完整指导，包括测试方法、评估指标、数据生成和报告撰写。

## 目录

1. [测试目标](#测试目标)
2. [测试环境准备](#测试环境准备)
3. [测试数据生成](#测试数据生成)
4. [性能指标说明](#性能指标说明)
5. [如何进行性能测试](#如何进行性能测试)
6. [结果分析方法](#结果分析方法)
7. [如何撰写测试报告](#如何撰写测试报告)

---

## 测试目标

根据项目要求，性能测试需要评估以下内容：

### 1. 性能与资源约束
- **时间复杂度评估**: 分析各个核心操作的时间复杂度
- **内存占用估算**: 测量不同负载下的内存使用情况
- **吞吐量与延迟**: 评估系统在不同输入速率下的处理能力

### 2. 测试内容
- 不同负载规模下的性能表现（小、中、大规模数据）
- 系统响应时间和处理延迟
- 峰值内存占用
- CPU 利用率
- 吞吐量（每秒处理句子数）

---

## 测试环境准备

### 1. 系统要求

```bash
# 检查系统信息
uname -a                    # 操作系统
lscpu                       # CPU 信息
free -h                     # 内存信息
g++ --version              # 编译器版本
```

### 2. 安装测试工具

#### Linux/Unix 系统

```bash
# 安装性能监控工具
sudo apt-get install time sysstat htop  # Ubuntu/Debian
sudo yum install time sysstat htop      # CentOS/RHEL

# 验证安装
/usr/bin/time --version
iostat -V
```

#### 可选工具

- **valgrind**: 内存泄漏检测
- **perf**: 性能分析
- **gprof**: 程序性能分析

```bash
# 安装 valgrind
sudo apt-get install valgrind

# 内存泄漏检测示例
valgrind --leak-check=full ./hotword input.txt output.txt
```

### 3. 编译配置

确保使用优化选项编译：

```bash
# 查看 Makefile 中的编译选项
grep CXXFLAGS Makefile

# 应该包含 -O2 优化标志
# CXXFLAGS = -std=c++11 -Wall -O2
```

---

## 测试数据生成

### 1. 使用自动化脚本

项目提供了 `performance_test.sh` 脚本，可以自动生成测试数据：

```bash
# 运行完整测试（包括数据生成）
bash performance_test.sh
```

生成的测试数据包括：
- **小规模**: 100 条句子
- **中规模**: 1000 条句子
- **大规模**: 5000 条句子

### 2. 手动生成测试数据

如果需要自定义测试数据，可以创建以下格式的文件：

```text
[HH:MM:SS]句子内容1
[HH:MM:SS]句子内容2
[HH:MM:SS]句子内容3
...
ACTION K=10
```

**示例 Python 脚本生成测试数据**:

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import random
from datetime import datetime, timedelta

# 词汇库
words = [
    "人工智能", "机器学习", "深度学习", "神经网络",
    "自然语言处理", "计算机视觉", "大数据", "云计算"
]

# 句子模板
templates = [
    "今天{}发展迅速，{}将改变世界。",
    "{}技术在{}领域取得重大突破。",
    "未来{}将与{}深度融合，推动社会进步。"
]

def generate_test_data(filename, num_sentences):
    current_time = datetime.strptime("10:00:00", "%H:%M:%S")
    
    with open(filename, 'w', encoding='utf-8') as f:
        for _ in range(num_sentences):
            template = random.choice(templates)
            w1, w2 = random.sample(words, 2)
            sentence = template.format(w1, w2)
            
            time_str = current_time.strftime("[%H:%M:%S]")
            f.write(f"{time_str}{sentence}\n")
            
            # 每句间隔 1-3 秒
            current_time += timedelta(seconds=random.randint(1, 3))
        
        # 添加查询命令
        f.write("ACTION K=10\n")

# 生成不同规模的测试数据
generate_test_data("test_small.txt", 100)
generate_test_data("test_medium.txt", 1000)
generate_test_data("test_large.txt", 5000)
```

### 3. 数据特征说明

- **时间戳**: 使用 `[HH:MM:SS]` 格式，确保时间递增
- **句子内容**: 包含足够的中文词汇，确保分词有效
- **数据分布**: 
  - 均匀分布：每句间隔相同
  - 突发分布：某些时间段句子密集
  - 稀疏分布：长时间间隔

---

## 性能指标说明

### 1. 时间相关指标

#### 执行时间 (Execution Time)
- **定义**: 程序从开始到结束的总时间
- **测量方法**: 
  ```bash
  /usr/bin/time -v ./hotword input.txt output.txt
  ```
- **关注点**: 
  - 用户时间 (User time)
  - 系统时间 (System time)
  - 挂钟时间 (Wall clock time)

#### 吞吐量 (Throughput)
- **定义**: 单位时间内处理的句子数量
- **计算公式**: `吞吐量 = 句子总数 / 执行时间`
- **单位**: 句/秒 (sentences/second)

#### 延迟 (Latency)
- **定义**: 单个操作的响应时间
- **测量**: 
  - 分词延迟
  - 窗口更新延迟
  - Top-K 查询延迟

### 2. 内存相关指标

#### 峰值内存 (Peak Memory)
- **定义**: 程序运行期间的最大内存占用
- **测量方法**:
  ```bash
  /usr/bin/time -v ./hotword input.txt output.txt 2>&1 | grep "Maximum resident"
  ```
- **单位**: KB 或 MB

#### 内存增长率
- **定义**: 随数据量增加，内存占用的增长趋势
- **分析**: 绘制数据量 vs 内存占用曲线

### 3. CPU 相关指标

#### CPU 使用率
- **定义**: 程序消耗的 CPU 资源百分比
- **测量方法**:
  ```bash
  /usr/bin/time -v ./hotword input.txt output.txt 2>&1 | grep "Percent of CPU"
  ```

### 4. 复杂度分析

#### 时间复杂度

| 操作 | 复杂度 | 说明 |
|------|--------|------|
| 分词 | O(n*m) | n=句子数, m=平均长度 |
| 词频统计 | O(1) | 哈希表插入/更新 |
| 窗口维护 | O(k) | k=窗口内词条数 |
| Top-K 查询 | O(n log k) | n=不同词数, k=Top-K |

#### 空间复杂度

| 数据结构 | 复杂度 | 说明 |
|---------|--------|------|
| 词频哈希表 | O(w) | w=不同词汇数 |
| 滑动窗口 | O(k) | k=窗口内词条数 |
| 分词词典 | O(d) | d=词典大小（固定） |

---

## 如何进行性能测试

### 方法一：使用自动化脚本（推荐）

```bash
# 1. 确保在项目根目录
cd /path/to/myProjectGit

# 2. 运行性能测试脚本
bash performance_test.sh

# 3. 查看测试结果
cat performance_tests/results/performance_summary.md
```

脚本会自动完成：
1. 编译程序
2. 生成测试数据（小、中、大三种规模）
3. 运行性能测试
4. 收集性能指标
5. 生成总结报告

### 方法二：手动测试

#### 步骤 1: 编译程序

```bash
make clean
make
```

#### 步骤 2: 准备测试数据

创建或使用现有测试文件（如 `input1.txt`）。

#### 步骤 3: 运行性能测试

```bash
# 使用 time 命令测量时间
/usr/bin/time -v ./hotword input1.txt output1.txt 2> time_output.txt

# 查看时间统计
cat time_output.txt
```

#### 步骤 4: 测量内存占用

**方法 A: 使用 /usr/bin/time**

```bash
/usr/bin/time -v ./hotword input.txt output.txt 2>&1 | grep -E "Maximum resident|User time|System time"
```

**方法 B: 使用 valgrind（更详细）**

```bash
valgrind --tool=massif --massif-out-file=massif.out ./hotword input.txt output.txt
ms_print massif.out > memory_report.txt
```

**方法 C: 使用 /usr/bin/time 配合脚本**

```bash
#!/bin/bash
for input in small.txt medium.txt large.txt; do
    echo "Testing $input"
    /usr/bin/time -f "Time: %E, Memory: %M KB" ./hotword $input output_$input
done
```

#### 步骤 5: 测量 CPU 使用率

```bash
# 在后台运行程序
./hotword large_input.txt output.txt &
PID=$!

# 使用 top 监控
top -b -p $PID -n 10 > cpu_usage.txt

# 或使用 ps
while kill -0 $PID 2>/dev/null; do
    ps -p $PID -o %cpu,%mem,vsz,rss
    sleep 1
done
```

### 方法三：压力测试

测试系统在极限条件下的表现：

```bash
# 生成超大规模数据
python3 generate_data.py --size 50000 --output huge_test.txt

# 运行测试
/usr/bin/time -v ./hotword huge_test.txt huge_output.txt
```

### 方法四：并发测试（如果系统支持）

```bash
# 同时运行多个实例
for i in {1..5}; do
    ./hotword input$i.txt output$i.txt &
done
wait
```

---

## 结果分析方法

### 1. 收集数据

创建一个 Excel 或 CSV 文件记录测试结果：

| 测试规模 | 句子数 | 执行时间(s) | 内存(MB) | CPU(%) | 吞吐量(句/s) |
|---------|--------|------------|---------|--------|-------------|
| 小规模   | 100    | 0.45       | 150     | 95     | 222         |
| 中规模   | 1000   | 0.52       | 151     | 98     | 1923        |
| 大规模   | 5000   | 0.65       | 155     | 99     | 7692        |

### 2. 绘制性能曲线

#### 吞吐量曲线

```python
import matplotlib.pyplot as plt

sizes = [100, 1000, 5000]
throughput = [222, 1923, 7692]

plt.plot(sizes, throughput, marker='o')
plt.xlabel('句子数量')
plt.ylabel('吞吐量 (句/秒)')
plt.title('不同负载下的吞吐量')
plt.grid(True)
plt.savefig('throughput.png')
```

#### 内存占用曲线

```python
memory = [150, 151, 155]

plt.plot(sizes, memory, marker='s', color='red')
plt.xlabel('句子数量')
plt.ylabel('内存占用 (MB)')
plt.title('不同负载下的内存占用')
plt.grid(True)
plt.savefig('memory.png')
```

### 3. 性能分析要点

#### 扩展性分析
- 吞吐量是否随数据量线性增长？
- 内存占用是否可控？
- 是否存在性能瓶颈？

#### 瓶颈识别
- CPU 密集型还是 I/O 密集型？
- 分词操作耗时占比
- 内存分配是否频繁？

#### 优化方向
- 算法优化空间
- 数据结构改进
- 并行化可能性

---

## 如何撰写测试报告

### 报告结构

一份完整的性能测试报告应包含以下部分：

#### 1. 封面信息
- 报告标题
- 系统名称和版本
- 测试日期
- 测试人员

#### 2. 测试环境（必须）
- 硬件配置（CPU、内存、存储）
- 操作系统及版本
- 编译器及编译选项
- 依赖库版本

**示例**:
```markdown
## 测试环境

- **操作系统**: Ubuntu 22.04.3 LTS
- **CPU**: AMD EPYC 7763 64-Core Processor @ 2.44GHz
- **内存**: 16 GB DDR4
- **编译器**: g++ (Ubuntu 11.4.0) 11.4.0
- **编译选项**: -std=c++11 -O2 -Wall
- **测试时间**: 2024-01-15 14:30:00
```

#### 3. 数据生成方式（必须）
- 测试数据规模
- 数据生成方法
- 数据特征描述

**示例**:
```markdown
## 测试数据

### 数据规模
- 小规模: 100 条句子
- 中规模: 1000 条句子  
- 大规模: 5000 条句子

### 生成方式
使用自动化脚本生成，包含随机中文语料，时间戳递增。

### 数据特征
- 平均句子长度: 20-30 字符
- 词汇多样性: 30+ 不同词汇
- 时间间隔: 1-3 秒/句
```

#### 4. 性能指标与图表（必须）

**表格形式**:
```markdown
## 性能测试结果

| 负载规模 | 句子数 | 执行时间 | 内存占用 | 吞吐量 | CPU使用率 |
|---------|--------|---------|---------|--------|----------|
| 小规模   | 100    | 0.45s   | 150MB   | 222句/s | 95%     |
| 中规模   | 1000   | 0.52s   | 151MB   | 1923句/s| 98%     |
| 大规模   | 5000   | 0.65s   | 155MB   | 7692句/s| 99%     |
```

**图表** (如果可能):
- 吞吐量对比图
- 内存占用趋势图
- 响应时间分布图

#### 5. 时间复杂度分析（必须）

```markdown
## 时间复杂度分析

### 核心操作复杂度

1. **分词操作**: O(n×m)
   - n: 句子数量
   - m: 平均句子长度
   - 分析: 使用 jieba 分词，复杂度取决于具体实现

2. **词频统计**: O(1)
   - 使用哈希表，插入和查找都是常数时间
   
3. **窗口维护**: O(k)
   - k: 窗口内词条数
   - 需要遍历窗口清除过期数据

4. **Top-K 查询**: O(n log k)
   - n: 不同词汇数
   - 使用优先队列实现
```

#### 6. 内存占用分析（必须）

```markdown
## 内存占用分析

### 主要内存消耗

1. **分词词典**: 约 100-120 MB（固定开销）
2. **词频哈希表**: O(w)，w 为不同词汇数
   - 小规模: ~5 MB
   - 中规模: ~8 MB
   - 大规模: ~12 MB
3. **滑动窗口**: O(k)，k 为窗口内词条数
   - 取决于窗口大小和数据密度

### 内存增长趋势

随着数据量增加，内存占用呈次线性增长，主要受词汇多样性影响。
```

#### 7. 不同负载下的吞吐量与延迟（必须）

```markdown
## 吞吐量与延迟分析

### 吞吐量

| 输入速率 | 实际吞吐量 | 处理延迟 |
|---------|-----------|---------|
| 低速(10句/s) | 10句/s | <1ms |
| 中速(100句/s) | 100句/s | 2-5ms |
| 高速(1000句/s) | 850句/s | 10-20ms |

### 延迟分析

- **平均延迟**: 约 5ms/句
- **P95延迟**: 约 15ms/句
- **P99延迟**: 约 25ms/句
```

#### 8. 性能瓶颈与优化建议

```markdown
## 性能瓶颈

1. **分词操作**: 占总时间的 60-70%
2. **I/O 操作**: 小规模数据时占比较高
3. **内存分配**: 频繁的对象创建和销毁

## 优化建议

1. 使用更高效的分词算法
2. 实现内存池减少分配开销
3. 批量处理提高 I/O 效率
4. 考虑多线程并行处理
```

#### 9. 结论与总结

```markdown
## 结论

系统在各种负载下表现稳定，具备以下特点：

✅ **良好的扩展性**: 吞吐量随数据量近似线性增长
✅ **可控的资源占用**: 内存占用稳定，无明显泄漏
✅ **高效的处理能力**: 单线程可达 7000+ 句/秒

⚠️ **改进空间**: 分词性能可进一步优化
```

### 报告撰写技巧

1. **客观准确**: 数据要真实可靠
2. **图文并茂**: 使用表格和图表增强可读性
3. **分析透彻**: 不仅展示数据，还要分析原因
4. **结构清晰**: 使用标题、列表、代码块等格式
5. **可重现**: 提供足够信息让他人能重现测试

### 常见错误

❌ 只列数据，不做分析
❌ 测试环境描述不清
❌ 缺少复杂度分析
❌ 没有优化建议
❌ 结论不明确

---

## 附录：常用测试命令

### A. 时间测量

```bash
# 基本计时
time ./hotword input.txt output.txt

# 详细统计
/usr/bin/time -v ./hotword input.txt output.txt

# 自定义格式
/usr/bin/time -f "Time: %E, Memory: %M KB" ./hotword input.txt output.txt
```

### B. 内存分析

```bash
# Valgrind 内存检查
valgrind --leak-check=full ./hotword input.txt output.txt

# Massif 内存分析
valgrind --tool=massif ./hotword input.txt output.txt
ms_print massif.out.* > memory_analysis.txt

# 实时监控
watch -n 1 "ps aux | grep hotword | grep -v grep"
```

### C. CPU 分析

```bash
# perf 性能分析
perf record ./hotword input.txt output.txt
perf report

# gprof 分析（需要编译时加 -pg）
g++ -pg -std=c++11 main.cpp -o hotword
./hotword input.txt output.txt
gprof hotword gmon.out > analysis.txt
```

### D. 综合监控

```bash
# htop 实时监控
htop -p $(pgrep hotword)

# iostat I/O 监控
iostat -x 1

# 系统资源监控
sar -u -r 1 10 > system_stats.txt
```

---

## 参考资源

- [Linux Performance Tools](https://www.brendangregg.com/linuxperf.html)
- [GNU Time Manual](https://www.gnu.org/software/time/)
- [Valgrind Documentation](https://valgrind.org/docs/manual/manual.html)
- [Performance Testing Best Practices](https://www.guru99.com/performance-testing.html)

---

**文档版本**: v1.0  
**最后更新**: 2024-01-15  
**维护者**: 热词统计系统开发团队
